```{r, include = FALSE}
library(tidyverse)
library(tidymodels)
library(mice) #package for imputation
library(VIM) #visualizing missingness
library(ranger) #for random forests
library(randomForest) #also for random forests
library(caret)
library(skimr)
library(GGally)
library(gridExtra)
library(vip) #variable importance
```

```{r}
library(readr)
drug_data_2 <- read_csv("drug_data-2.csv")
drug = drug_data_2
names(drug) = c("ID", "Age", "Gender", "Education", "Country", "Ethnicity",
"Nscore", "Escore", "Oscore", "Ascore", "Cscore", "Impulsive",
"SS", "Alcohol", "Amphet", "Amyl", "Benzos", "Caff", "Cannabis",
"Choc", "Coke", "Crack", "Ecstasy", "Heroin", "Ketamine", "Legalh",
"LSD", "Meth", "Mushrooms", "Nicotine", "Semer", "VSA")

#str(drug)

drug[drug == "CL0"] = "No"
drug[drug == "CL1"] = "No"
drug[drug == "CL2"] = "Yes"
drug[drug == "CL3"] = "Yes"
drug[drug == "CL4"] = "Yes"
drug[drug == "CL5"] = "Yes"
drug[drug == "CL6"] = "Yes"

#str(drug)

drug_clean = drug %>% mutate_at(vars(Age:Ethnicity), funs(as_factor)) %>%
mutate(Age = factor(Age, labels = c("18_24", "25_34", "35_44", "45_54",
"55_64", "65_"))) %>%
mutate(Gender = factor(Gender, labels = c("Male", "Female"))) %>%
mutate(Education = factor(Education, labels = c("Under16", "At16", "At17", "At18",
"SomeCollege","ProfessionalCert",
"Bachelors", "Masters",
"Doctorate"))) %>%
mutate(Country = factor(Country, labels = c("USA", "NewZealand", "Other", "Australia",
"Ireland","Canada","UK"))) %>%
mutate(Ethnicity = factor(Ethnicity, labels = c("Black", "Asian", "White",
"White/Black", "Other",
"White/Asian", "Black/Asian"))) %>%
mutate_at(vars(Alcohol:VSA), funs(as_factor)) %>%
select(-ID)

#str(drug_clean)

drug_clean = drug_clean %>% select(!(Alcohol:Mushrooms)) %>% select(!(Semer:VSA))

str(drug_clean)
skim(drug_clean)
```
Q1 **Fals**

Data split

```{r}
set.seed(1234) 
drug_split = initial_split(drug_clean, prop = 0.7, strata = Nicotine) #70% in training
train = training(drug_split)
test = testing(drug_split)
```

Q2 **1318**

Visualization  
```{r}
p1 = ggplot(drug_clean, aes(x = Age, fill = Nicotine)) + geom_bar(position = "fill")
p2 = ggplot(drug_clean, aes(x = Gender, fill = Nicotine)) + geom_bar(position = "fill")
p3 = ggplot(drug_clean, aes(x = Education, fill = Nicotine)) + geom_bar(position = "fill")

grid.arrange(p1,p2,p3)
```
Q3 **False**



```{r}
p4 = ggplot(drug_clean, aes(x = Country, fill = Nicotine)) + geom_bar(position = "fill")
p5 = ggplot(drug_clean, aes(x = Ethnicity, fill = Nicotine)) + geom_bar(position = "fill")
grid.arrange(p4,p5)
```


```{r}
p7 = ggplot(drug_clean, aes(x = Nicotine, y = Nscore)) + geom_boxplot()
p8 = ggplot(drug_clean, aes(x = Nicotine, y = Escore)) + geom_boxplot()
p9 = ggplot(drug_clean, aes(x = Nicotine, y = Oscore)) + geom_boxplot()
p10 = ggplot(drug_clean, aes(x = Nicotine, y = Ascore)) + geom_boxplot()

grid.arrange(p7,p8,p9,p10, ncol = 2)
```

```{r}
p11 = ggplot(drug_clean, aes(x = Nicotine, y = Cscore)) + geom_boxplot()
p12 = ggplot(drug_clean, aes(x = Nicotine, y = Impulsive)) + geom_boxplot()
p13 = ggplot(drug_clean, aes(x = Nicotine, y = SS)) + geom_boxplot()
grid.arrange(p11,p12,p13, ncol = 2)
```

Q4 **True**

Set up our folds for cross-validation  
```{r}
set.seed(123)
rf_folds = vfold_cv(train, v = 5)
```

Random forest with an R-defined tuning grid (this model took about 5 minutes to run)
```{r}
drug_recipe = recipe(Nicotine ~., train) %>%
  step_dummy(all_nominal(), -all_outcomes())

rf_model = rand_forest(mtry = tune(), min_n = tune(), trees = 100) %>% #add tuning of mtry and min_n parameters
  #setting trees to 100 here should also speed things up a bit, but more trees might be better
  set_engine("ranger", importance = "permutation") %>% #added importance metric
  set_mode("classification")

drug_wflow = 
  workflow() %>% 
  add_model(rf_model) %>% 
  add_recipe(drug_recipe)

set.seed(123)
rf_res = tune_grid(
  drug_wflow,
  resamples = rf_folds,
  grid = 10 #try 20 different combinations of the random forest tuning parameters
)
```

```{r}
rf_res %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "Accuracy")
```


Refining the parameters  
```{r}
drug_recipe = recipe(Nicotine ~., train) %>%
  step_dummy(all_nominal(), -all_outcomes())

rf_model = rand_forest(mtry = tune(), min_n = tune(), trees = 100) %>% #add tuning of mtry and min_n parameters
  #setting trees to 100 here should also speed things up a bit, but more trees might be better
  set_engine("ranger", importance = "permutation") %>% #added importance metric
  set_mode("classification")

drug_wflow = 
  workflow() %>% 
  add_model(rf_model) %>% 
  add_recipe(drug_recipe)

rf_grid = grid_regular(
  mtry(range = c(2, 8)), #these values determined through significant trial and error
  min_n(range = c(5, 20)), #these values determined through significant trial and error
  levels = 5
)

set.seed(123)
rf_res_tuned = tune_grid(
  drug_wflow,
  resamples = rf_folds,
  grid = rf_grid #use the tuning grid
)
```

```{r}
rf_res_tuned %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "Accuracy")
```

```{r}
rf_res_tuned %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  mutate(min_n = factor(min_n)) %>%
  ggplot(aes(mtry, mean, color = min_n)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "Accuracy")
```

Q5 **0.725**







```{r}
best_rf = select_best(rf_res_tuned, "accuracy")

final_rf = finalize_workflow(
  drug_wflow,
  best_rf
)

final_rf
```

```{r}
#fit the finalized workflow to our training data
final_rf_fit = fit(final_rf, train)
```

Check out variable importance
```{r}
final_rf_fit %>% pull_workflow_fit() %>% vip(geom = "point")
```



Q6: **SS**


Predictions  
```{r}
trainpredrf = predict(final_rf_fit, train)
head(trainpredrf)
```


Confusion matrix
```{r}
confusionMatrix(trainpredrf$.pred_class, train$Nicotine, 
                positive = "Yes")

```


Q7 **0.9082**

Q8 **0.6707**


Predictions test 
```{r}
trainpredrf = predict(final_rf_fit, test)
head(trainpredrf)
confusionMatrix(trainpredrf$.pred_class, test$Nicotine, 
                positive = "Yes")
```
Q9 **0.7037**

Q10 **B- Likly Over Fitting**
